name: Upload to S3 and Deploy CloudFormation stack

on:
  push:
    branches:
      - main

jobs:
  deploy:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        deployment: [docker, s3, cloudformation]
    steps:
    - name: Checkout code
      uses: actions/checkout@v2

    - name: Set up AWS credentials
      uses: aws-actions/configure-aws-credentials@v1
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-west-2

    - name: Dockerize data_quality_checks file and push to ECR
      if: matrix.deployment == 'docker' 
      env:
        ECR_REGISTRY: ${{ env.ECR_REGISTRY }}
        ECR_REPOSITORY: data-quality-ecr
      run: |
        cd data_quality_checks/
        docker build -t data-quality-ecr .
        docker tag data-quality-ecr:latest $ECR_REGISTRY/data-quality-ecr:latest
        aws ecr get-login-password --region us-west-2 | docker login --username AWS --password-stdin $ECR_REGISTRY
        docker push $ECR_REGISTRY/$ECR_REPOSITORY:latest

    - name: Upload spark-app.py to S3
      if: matrix.deployment == 's3' && success() && needs.deploy.result == 'success'
      uses: docker://amazon/aws-cli:2.0.7
      with:
        args: s3 cp simple-pyspark-app.py s3://mysparkawsbucket/spark-app.py
        

    - name: Deploy CloudFormation stack
      if: matrix.deployment == 'cloudformation' && success() && needs.deploy.result == 'success'
      uses: aws-actions/aws-cloudformation-github-deploy@v1.1.0
      with:
        template: cloudformation/cloudformation.yml
        name: my-cloudformation-stack
        capabilities: CAPABILITY_NAMED_IAM
